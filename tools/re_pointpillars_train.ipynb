{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _init_path\n",
    "import argparse\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from test import repeat_eval_ckpt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from pcdet.config import cfg, cfg_from_list, cfg_from_yaml_file, log_config_to_file\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.models import build_network, model_fn_decorator\n",
    "from pcdet.utils import common_utils\n",
    "from train_utils.optimization import build_optimizer, build_scheduler\n",
    "from train_utils.train_utils import train_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载配置文件,文件定义了数据路径、类型个数、训练参数等等详细内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_file = \"./cfgs/kitti_models/pointpillar.yaml\"\n",
    "cfg = cfg_from_yaml_file(cfg_file, cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/anaconda3/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PointPillar(\n",
       "  (vfe): PillarVFE(\n",
       "    (pfn_layers): ModuleList(\n",
       "      (0): PFNLayer(\n",
       "        (linear): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (norm): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (backbone_3d): None\n",
       "  (map_to_bev_module): PointPillarScatter()\n",
       "  (pfe): None\n",
       "  (backbone_2d): BaseBEVBackbone(\n",
       "    (blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (2): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (3): ReLU()\n",
       "        (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (5): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (6): ReLU()\n",
       "        (7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (8): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (9): ReLU()\n",
       "        (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (11): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (12): ReLU()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (3): ReLU()\n",
       "        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (5): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (6): ReLU()\n",
       "        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (8): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (9): ReLU()\n",
       "        (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (11): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (12): ReLU()\n",
       "        (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (14): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (15): ReLU()\n",
       "        (16): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (17): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (18): ReLU()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (3): ReLU()\n",
       "        (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (5): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (6): ReLU()\n",
       "        (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (8): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (9): ReLU()\n",
       "        (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (11): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (12): ReLU()\n",
       "        (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (14): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (15): ReLU()\n",
       "        (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (17): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (18): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (deblocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense_head): AnchorHeadSingle(\n",
       "    (cls_loss_func): SigmoidFocalClassificationLoss()\n",
       "    (reg_loss_func): WeightedSmoothL1Loss()\n",
       "    (dir_loss_func): WeightedCrossEntropyLoss()\n",
       "    (conv_cls): Conv2d(384, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_box): Conv2d(384, 42, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_dir_cls): Conv2d(384, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (point_head): None\n",
       "  (roi_head): None\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_train = False \n",
    "BatchSize = 1\n",
    "Workers = 4\n",
    "# -----------------------create dataloader & network & optimizer---------------------------\n",
    "train_set, train_loader, train_sampler = build_dataloader(\n",
    "    dataset_cfg=cfg.DATA_CONFIG,\n",
    "    class_names=cfg.CLASS_NAMES,\n",
    "    batch_size=BatchSize,\n",
    "    dist=dist_train, workers=Workers,\n",
    "    logger=None,\n",
    "    training=True,\n",
    "    merge_all_iters_to_one_epoch=False,\n",
    "    total_epochs=None\n",
    ")\n",
    "\n",
    "model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), dataset=train_set)\n",
    "# if args.sync_bn:\n",
    "#     model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "model.cuda()\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = build_optimizer(model, cfg.OPTIMIZATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load checkpoint if it is possible\n",
    "ckpt_dir = \"./tempckpt/\"\n",
    "start_epoch = it = 0\n",
    "last_epoch = -1\n",
    "\n",
    "lr_scheduler, lr_warmup_scheduler = build_scheduler(\n",
    "    optimizer, total_iters_each_epoch=len(train_loader), total_epochs=50,\n",
    "    last_epoch=last_epoch, optim_cfg=cfg.OPTIMIZATION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs:   0%|          | 0/50 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "epochs:   0%|          | 0/50 [00:00<?, ?it/s, loss=1.45, lr=0.0003, d_time=0.15(0.15), f_time=0.10(0.10), b_time=0.32(0.32)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "epochs:   0%|          | 0/50 [00:00<?, ?it/s, loss=1.28, lr=0.0003, d_time=0.01(0.08), f_time=0.06(0.08), b_time=0.13(0.22)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "epochs:   0%|          | 0/50 [00:01<?, ?it/s, loss=1.33, lr=0.0003, d_time=0.00(0.05), f_time=0.04(0.06), b_time=0.10(0.18)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "epochs:   0%|          | 0/50 [00:01<?, ?it/s, loss=1.43, lr=0.0003, d_time=0.00(0.04), f_time=0.04(0.06), b_time=0.11(0.16)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "epochs:   0%|          | 0/50 [00:01<?, ?it/s, loss=1.45, lr=0.0003, d_time=0.00(0.03), f_time=0.03(0.05), b_time=0.10(0.15)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "epochs:   0%|          | 0/50 [00:01<?, ?it/s, loss=1.27, lr=0.0003, d_time=0.00(0.03), f_time=0.04(0.05), b_time=0.10(0.14)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "epochs:   0%|          | 0/50 [00:01<?, ?it/s, loss=1.36, lr=0.0003, d_time=0.00(0.02), f_time=0.05(0.05), b_time=0.11(0.14)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "epochs:   0%|          | 0/50 [00:01<?, ?it/s, loss=1.64, lr=0.0003, d_time=0.00(0.02), f_time=0.04(0.05), b_time=0.11(0.13)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "epochs:   0%|          | 0/50 [00:01<?, ?it/s, loss=1.4, lr=0.0003, d_time=0.00(0.02), f_time=0.05(0.05), b_time=0.11(0.13)] Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f5ba41bcdc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/charles/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/charles/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1301, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/charles/anaconda3/lib/python3.9/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/charles/anaconda3/lib/python3.9/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/home/charles/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 936, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/charles/anaconda3/lib/python3.9/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "model.train() \n",
    "\n",
    "train_model(\n",
    "    model,\n",
    "    optimizer,\n",
    "    train_loader,\n",
    "    model_func=model_fn_decorator(),\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    optim_cfg=cfg.OPTIMIZATION,\n",
    "    start_epoch=0,\n",
    "    total_epochs=50,\n",
    "    start_iter=it,\n",
    "    rank=0,\n",
    "    tb_log=None,\n",
    "    ckpt_save_dir=ckpt_dir,\n",
    "    train_sampler=train_sampler,\n",
    "    lr_warmup_scheduler=lr_warmup_scheduler,\n",
    "    ckpt_save_interval=1,\n",
    "    max_ckpt_save_num=50,\n",
    "    merge_all_iters_to_one_epoch=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be59c0aa2c1e192ef7afd22392aaf33d8b2449179640b24bdb1e1e8b645b56b6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
